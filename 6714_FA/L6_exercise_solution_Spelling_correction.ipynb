{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Boring preliminaries\n",
    "%pylab inline\n",
    "import re\n",
    "import math\n",
    "import string\n",
    "from collections import Counter\n",
    "from __future__ import division\n",
    "\n",
    "# %pylab inline causes numpy.sum() overriding builtin's sum(). \n",
    "import builtins as base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6488666"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save space\n",
    "import gzip\n",
    "with gzip.open('./big.txt.gz', 'rt') as f:\n",
    "    TEXT = f.read()\n",
    "\n",
    "len(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens(text):\n",
    "    \"List all the word tokens (consecutive letters) in a text. Normalize to lowercase.\"\n",
    "    return re.findall('[a-z]+', text.lower()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'a', 'test', 'this', 'is']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens('This is: A test, 1, 2, 3, this is.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1105285"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORDS = tokens(TEXT)\n",
    "len(WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'the', 'adventures', 'of', 'sherlock', 'holmes']\n"
     ]
    }
   ],
   "source": [
    "print(WORDS[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(bag, n=10):\n",
    "    \"Sample a random n-word sentence from the model described by the bag of words.\"\n",
    "    return ' '.join(random.choice(bag) for _ in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lactate of and the seventy who growth now at rostov'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 2, 'is': 2, 'it': 1, 'test': 2, 'this': 1})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(tokens('Is this a test? It is a test!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 80030), ('of', 40025), ('and', 38313), ('to', 28766), ('in', 22050), ('a', 21155), ('that', 12512), ('he', 12401), ('was', 11410), ('it', 10681)]\n"
     ]
    }
   ],
   "source": [
    "COUNTS = Counter(WORDS)\n",
    "\n",
    "print(COUNTS.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80030 the\n",
      "83 rare\n",
      "38313 and\n",
      "0 neverbeforeseen\n",
      "460 words\n"
     ]
    }
   ],
   "source": [
    "for w in tokens('the rare and neverbeforeseen words'):\n",
    "    print(COUNTS[w], w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEOCAYAAACO+Hw9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncwaNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1126859b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "M = COUNTS['the']\n",
    "yscale('log'); xscale('log'); title('Frequency of n-th most frequent word and 1/n line.')\n",
    "plot([c for (w, c) in COUNTS.most_common()])\n",
    "plot([M/i for i in range(1, len(COUNTS)+1)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actress: 7\n",
      "cress: 0\n",
      "caress: 3\n",
      "access: 56\n",
      "across: 222\n",
      "acres: 36\n"
     ]
    }
   ],
   "source": [
    "cands = ['actress', 'cress', 'caress', 'access', 'across', 'acres']\n",
    "pairs = [(w, COUNTS[w]) for w in cands]\n",
    "for pair in pairs:\n",
    "    print('{}: {}'.format(pair[0], pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "across / access in the bigw corpus = 3.9642857142857144\n",
      "across / access in the COCA corpus = 3.2627031697175872\n"
     ]
    }
   ],
   "source": [
    "print('across / access in the bigw corpus =', 222.0 / 56)\n",
    "print('across / access in the COCA corpus =', 120844.0 / 37038)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1105285"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.sum(COUNTS.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pdist(counter):\n",
    "    \"Make a probability distribution, given evidence from a Counter.\"\n",
    "    N = int(base.sum(counter.values()))\n",
    "    return lambda x: counter[x]/N\n",
    "\n",
    "P = pdist(COUNTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(actress) \t= 6.333208e-06\n",
      "P(cress) \t= 0.000000e+00\n",
      "P(caress) \t= 2.714232e-06\n",
      "P(access) \t= 5.066567e-05\n",
      "P(across) \t= 2.008532e-04\n",
      "P(acres) \t= 3.257078e-05\n"
     ]
    }
   ],
   "source": [
    "for w in cands:\n",
    "    print('P({}) \\t= {:8.6e}'.format(w, P(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def known(words):\n",
    "    \"Return the subset of words that are actually in the dictionary.\"\n",
    "    return {w for w in words if w in COUNTS}\n",
    "\n",
    "def edits0(word): \n",
    "    \"Return all strings that are zero edits away from word (i.e., just word itself).\"\n",
    "    return {word}\n",
    "\n",
    "def edits2(word):\n",
    "    \"Return all strings that are two edits away from this word.\"\n",
    "    return {e2 for e1 in edits1(word) for e2 in edits1(e1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edits1(word):\n",
    "    \"Return all strings that are one edit away from this word.\"\n",
    "    pairs      = splits(word)\n",
    "    deletes    = [a+b[1:]           for (a, b) in pairs if b]\n",
    "    transposes = [a+b[1]+b[0]+b[2:] for (a, b) in pairs if len(b) > 1]\n",
    "    replaces   = [a+c+b[1:]         for (a, b) in pairs for c in alphabet if b]\n",
    "    inserts    = [a+c+b             for (a, b) in pairs for c in alphabet]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def splits(word):\n",
    "    \"Return a list of all possible (first, rest) pairs that comprise word.\"\n",
    "    return [(word[:i], word[i:]) \n",
    "            for i in range(len(word)+1)]\n",
    "\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 'wird'), ('w', 'ird'), ('wi', 'rd'), ('wir', 'd'), ('wird', '')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits('wird')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wird'}\n"
     ]
    }
   ],
   "source": [
    "print(edits0('wird'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wdird', 'wirrd', 'qird', 'wzird', 'wirx', 'wibd', 'wirfd', 'wirdx', 'wiprd', 'wirb', 'wierd', 'wimrd', 'zwird', 'wird', 'wirc', 'wirid', 'nwird', 'wfrd', 'wprd', 'wrrd', 'wwrd', 'wirde', 'kird', 'wsrd', 'wirdh', 'wirhd', 'wirdp', 'wirt', 'wjrd', 'wqrd', 'wigrd', 'qwird', 'wpird', 'cwird', 'wirnd', 'wirpd', 'oird', 'kwird', 'wvrd', 'wiro', 'wyrd', 'bird', 'wired', 'wirxd', 'ywird', 'wirv', 'wyird', 'wmird', 'pird', 'wirdw', 'wiyd', 'pwird', 'winrd', 'wuird', 'wirdg', 'wxrd', 'wcird', 'wtird', 'wiard', 'wiud', 'wimd', 'wirwd', 'awird', 'wirds', 'wijd', 'wixd', 'wmrd', 'wifrd', 'wir', 'wirdi', 'wiord', 'wirdq', 'wnrd', 'wirdu', 'jird', 'weird', 'gird', 'wicd', 'wrid', 'wiry', 'waird', 'wirod', 'wirdt', 'wizd', 'wgird', 'wibrd', 'widr', 'wiid', 'wkrd', 'mwird', 'vwird', 'xird', 'wixrd', 'wiru', 'wirdm', 'wiri', 'wirdf', 'wirsd', 'wiryd', 'wiod', 'wirdz', 'wlird', 'wgrd', 'wirf', 'wiad', 'wihd', 'gwird', 'wirdc', 'lwird', 'wirzd', 'yird', 'uird', 'wire', 'wirdb', 'mird', 'wipd', 'wirw', 'word', 'dird', 'wilrd', 'owird', 'vird', 'wild', 'tird', 'wjird', 'wivd', 'wkird', 'woird', 'wirdn', 'wirg', 'sird', 'rird', 'hwird', 'widrd', 'wirq', 'fwird', 'wdrd', 'witd', 'wirdj', 'wirdy', 'wtrd', 'wiqd', 'wira', 'iwird', 'wwird', 'eird', 'wisd', 'wind', 'wirl', 'witrd', 'wnird', 'wfird', 'nird', 'wirk', 'uwird', 'wihrd', 'wiwrd', 'ewird', 'wirs', 'whird', 'wsird', 'xwird', 'wicrd', 'wiqrd', 'wirn', 'wiyrd', 'wirjd', 'wirqd', 'werd', 'swird', 'ward', 'wirp', 'wirld', 'aird', 'rwird', 'wirtd', 'wiird', 'wiwd', 'wikrd', 'wirdd', 'wircd', 'wqird', 'wrird', 'wirdk', 'whrd', 'dwird', 'wirud', 'wirbd', 'wirdo', 'wid', 'bwird', 'zird', 'wizrd', 'wbird', 'iird', 'cird', 'wirmd', 'wifd', 'ird', 'wikd', 'wvird', 'fird', 'wxird', 'iwrd', 'wied', 'wirvd', 'wurd', 'wiurd', 'wirm', 'wigd', 'wirgd', 'widd', 'wirad', 'wijrd', 'wrd', 'jwird', 'twird', 'wirr', 'hird', 'wcrd', 'wirj', 'wisrd', 'wirda', 'wirdv', 'wirkd', 'wirdl', 'wivrd', 'lird', 'wlrd', 'wirh', 'wirz', 'wirdr', 'wzrd', 'wbrd'}\n"
     ]
    }
   ],
   "source": [
    "print(edits1('wird'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24254\n"
     ]
    }
   ],
   "source": [
    "print(len(edits2('wird')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import exp\n",
    "\n",
    "BETA = 1.0\n",
    "\n",
    "def score(err, beta = BETA):\n",
    "    return exp(-beta * err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta = 0.5\tscore(1) = 0.6065306597126334\tscore(2) = 0.36787944117144233\n",
      "beta = 1.0\tscore(1) = 0.36787944117144233\tscore(2) = 0.1353352832366127\n",
      "beta = 1.5\tscore(1) = 0.22313016014842982\tscore(2) = 0.049787068367863944\n",
      "beta = 2.0\tscore(1) = 0.1353352832366127\tscore(2) = 0.01831563888873418\n"
     ]
    }
   ],
   "source": [
    "for b in [0.5, 1.0, 1.5, 2.0]:\n",
    "    print('beta = {}\\tscore(1) = {}\\tscore(2) = {}'.format(b, score(1, b), score(2, b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "words=re.compile('.*[A-Za-z0-9].*')\n",
    "filtered=[w for w in WORDS if words.match(w)]\n",
    "pairs=nltk.bigrams(filtered)\n",
    "fdist=nltk.FreqDist(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement bigram language model, we need to get bigram words and count their frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bigram(raw):\n",
    "    words=re.compile('.*[A-Za-z0-9].*')\n",
    "    filtered=[w for w in WORDS if words.match(w)]\n",
    "    pairs=nltk.bigrams(filtered)\n",
    "    fdist=nltk.FreqDist(pairs)\n",
    "    \n",
    "    return fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_info = get_bigram(WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the method to compute the prior using bigram language model(with add-1 smoothing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_bi_pro(cand):\n",
    "    count = []\n",
    "    for pair,c in bigram_info.items():\n",
    "        if pair[0] == cand and pair[1] == cand:\n",
    "            ##print(pair,c)\n",
    "            count.append(c)\n",
    "    N = COUNTS[cand]\n",
    "    return (sum(count) + 1)/(N + len(bigram_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the probability using bigram language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.35747884989e-06\n"
     ]
    }
   ],
   "source": [
    "a = compute_bi_pro('the')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80030"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COUNTS['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "def correct(word):\n",
    "    \"Find the best spelling correction for this word.\"\n",
    "    if known([word]):\n",
    "        print('Error: this function only works with words not in the dictionary.')\n",
    "        return word\n",
    "    \n",
    "    # get the candidates that are <=2 distance away from word\n",
    "    candidates = [(w, 1) for w in known(edits1(word))]\n",
    "    candidates.extend([(w, 2) for w in known(edits2(word))])\n",
    "    if len(candidates) == 0:\n",
    "        print('Warning: no candidate found for {}. I do not know how to correct it.'.format(word))\n",
    "        return word\n",
    "    # general case\n",
    "    \n",
    "    best_cand = None\n",
    "    best_prob = -1.0\n",
    "    for cand, err in candidates:\n",
    "        prob = compute_bi_pro(cand) * score(err)\n",
    "        # debug\n",
    "        if DEBUG:\n",
    "            print('.. c = {} (err = {}) => Prob = {} <= prior = {}, likelihood = {}'.format(\n",
    "                    cand, err, prob, P(cand), score(err)))\n",
    "        \n",
    "        if prob > best_prob: \n",
    "            best_cand = cand \n",
    "            best_prob = prob\n",
    "    \n",
    "    return best_cand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us implement the correction procedure and find the best candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. c = than (err = 1) => Prob = 9.677039780181408e-07 <= prior = 0.0010911212945077513, likelihood = 0.36787944117144233\n",
      ".. c = thaw (err = 1) => Prob = 9.707785429101824e-07 <= prior = 1.8094880505932859e-06, likelihood = 0.36787944117144233\n",
      ".. c = the (err = 1) => Prob = 1.6030268842128207e-06 <= prior = 0.07240666434449033, likelihood = 0.36787944117144233\n",
      ".. c = ta (err = 1) => Prob = 2.912304888191344e-06 <= prior = 5.428464151779858e-06, likelihood = 0.36787944117144233\n",
      ".. c = thy (err = 1) => Prob = 9.706632783588365e-07 <= prior = 4.252296918894222e-05, likelihood = 0.36787944117144233\n",
      ".. c = tea (err = 1) => Prob = 9.705096348617951e-07 <= prior = 9.680761070674079e-05, likelihood = 0.36787944117144233\n",
      ".. c = th (err = 1) => Prob = 9.70653033945579e-07 <= prior = 4.614194529012879e-05, likelihood = 0.36787944117144233\n",
      ".. c = tra (err = 1) => Prob = 9.707785429101824e-07 <= prior = 1.8094880505932859e-06, likelihood = 0.36787944117144233\n",
      ".. c = that (err = 1) => Prob = 3.4770947250042443e-05 <= prior = 0.011320157244511596, likelihood = 0.36787944117144233\n",
      ".. c = ha (err = 1) => Prob = 3.4941296592244135e-05 <= prior = 6.785580189724822e-05, likelihood = 0.36787944117144233\n",
      ".. c = shaw (err = 2) => Prob = 3.5712946786702493e-07 <= prior = 1.8094880505932859e-06, likelihood = 0.1353352832366127\n",
      ".. c = the (err = 2) => Prob = 5.897206343470109e-07 <= prior = 0.07240666434449033, likelihood = 0.1353352832366127\n",
      ".. c = them (err = 2) => Prob = 3.5503180349171205e-07 <= prior = 0.002027531360689777, likelihood = 0.1353352832366127\n",
      ".. c = ca (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = isa (err = 2) => Prob = 3.5712758305501367e-07 <= prior = 3.6189761011865717e-06, likelihood = 0.1353352832366127\n",
      ".. c = tow (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = tie (err = 2) => Prob = 3.571172169445615e-07 <= prior = 1.3571160379449644e-05, likelihood = 0.1353352832366127\n",
      ".. c = th (err = 2) => Prob = 3.5708329569926467e-07 <= prior = 4.614194529012879e-05, likelihood = 0.1353352832366127\n",
      ".. c = aah (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = shag (err = 2) => Prob = 3.5712758305501367e-07 <= prior = 3.6189761011865717e-06, likelihood = 0.1353352832366127\n",
      ".. c = thy (err = 2) => Prob = 3.5708706440828896e-07 <= prior = 4.252296918894222e-05, likelihood = 0.1353352832366127\n",
      ".. c = too (err = 2) => Prob = 3.566156517846231e-07 <= prior = 0.0004957997258625604, likelihood = 0.1353352832366127\n",
      ".. c = tut (err = 2) => Prob = 2.499846904587502e-06 <= prior = 9.952184278263072e-06, likelihood = 0.1353352832366127\n",
      ".. c = ten (err = 2) => Prob = 3.5692508172221614e-07 <= prior = 0.0001981389415399648, likelihood = 0.1353352832366127\n",
      ".. c = to (err = 2) => Prob = 2.3235405505688726e-06 <= prior = 0.02602586663168323, likelihood = 0.1353352832366127\n",
      ".. c = tug (err = 2) => Prob = 3.5712758305501367e-07 <= prior = 3.6189761011865717e-06, likelihood = 0.1353352832366127\n",
      ".. c = pea (err = 2) => Prob = 3.5711815929337193e-07 <= prior = 1.2666416354153001e-05, likelihood = 0.1353352832366127\n",
      ".. c = shan (err = 2) => Prob = 3.571172169445615e-07 <= prior = 1.3571160379449644e-05, likelihood = 0.1353352832366127\n",
      ".. c = tap (err = 2) => Prob = 3.5712192873834694e-07 <= prior = 9.047440252966429e-06, likelihood = 0.1353352832366127\n",
      ".. c = a (err = 2) => Prob = 1.0147457166596805e-06 <= prior = 0.01913985985515048, likelihood = 0.1353352832366127\n",
      ".. c = ida (err = 2) => Prob = 3.5712946786702493e-07 <= prior = 1.8094880505932859e-06, likelihood = 0.1353352832366127\n",
      ".. c = tasha (err = 2) => Prob = 3.5712946786702493e-07 <= prior = 1.8094880505932859e-06, likelihood = 0.1353352832366127\n",
      ".. c = ty (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = era (err = 2) => Prob = 3.5712192873834694e-07 <= prior = 9.047440252966429e-06, likelihood = 0.1353352832366127\n",
      ".. c = try (err = 2) => Prob = 3.5704938089746334e-07 <= prior = 7.871273020080794e-05, likelihood = 0.1353352832366127\n",
      ".. c = tat (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = chat (err = 2) => Prob = 3.5712287111202423e-07 <= prior = 8.142696227669786e-06, likelihood = 0.1353352832366127\n",
      ".. c = tu (err = 2) => Prob = 3.5712758305501367e-07 <= prior = 3.6189761011865717e-06, likelihood = 0.1353352832366127\n",
      ".. c = tt (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = tafa (err = 2) => Prob = 3.5712946786702493e-07 <= prior = 1.8094880505932859e-06, likelihood = 0.1353352832366127\n",
      ".. c = tea (err = 2) => Prob = 3.5703054212445775e-07 <= prior = 9.680761070674079e-05, likelihood = 0.1353352832366127\n",
      ".. c = ma (err = 2) => Prob = 3.5710214003992984e-07 <= prior = 2.8047064784195933e-05, likelihood = 0.1353352832366127\n",
      ".. c = thin (err = 2) => Prob = 3.5697497932462194e-07 <= prior = 0.00015018750819924273, likelihood = 0.1353352832366127\n",
      ".. c = tra (err = 2) => Prob = 3.5712946786702493e-07 <= prior = 1.8094880505932859e-06, likelihood = 0.1353352832366127\n",
      ".. c = what (err = 2) => Prob = 4.960425291815881e-06 <= prior = 0.002724184260168192, likelihood = 0.1353352832366127\n",
      ".. c = pua (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = txt (err = 2) => Prob = 3.57123813490675e-07 <= prior = 7.2379522023731435e-06, likelihood = 0.1353352832366127\n",
      ".. c = wa (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = team (err = 2) => Prob = 3.57123813490675e-07 <= prior = 7.2379522023731435e-06, likelihood = 0.1353352832366127\n",
      ".. c = toe (err = 2) => Prob = 3.5709742876830264e-07 <= prior = 3.2570784910679145e-05, likelihood = 0.1353352832366127\n",
      ".. c = tax (err = 2) => Prob = 3.5705220688488584e-07 <= prior = 7.599849812491801e-05, likelihood = 0.1353352832366127\n",
      ".. c = toy (err = 2) => Prob = 3.5712475587429926e-07 <= prior = 6.333208177076501e-06, likelihood = 0.1353352832366127\n",
      ".. c = ana (err = 2) => Prob = 3.5712946786702493e-07 <= prior = 1.8094880505932859e-06, likelihood = 0.1353352832366127\n",
      ".. c = twy (err = 2) => Prob = 3.5712852545853246e-07 <= prior = 2.714232075889929e-06, likelihood = 0.1353352832366127\n",
      ".. c = tin (err = 2) => Prob = 3.5712475587429926e-07 <= prior = 6.333208177076501e-06, likelihood = 0.1353352832366127\n",
      ".. c = sta (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = ton (err = 2) => Prob = 3.5712475587429926e-07 <= prior = 6.333208177076501e-06, likelihood = 0.1353352832366127\n",
      ".. c = te (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = tray (err = 2) => Prob = 3.57123813490675e-07 <= prior = 7.2379522023731435e-06, likelihood = 0.1353352832366127\n",
      ".. c = t (err = 2) => Prob = 3.558935470327918e-07 <= prior = 0.0011924526253409755, likelihood = 0.1353352832366127\n",
      ".. c = sca (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = rah (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = na (err = 2) => Prob = 3.5712852545853246e-07 <= prior = 2.714232075889929e-06, likelihood = 0.1353352832366127\n",
      ".. c = yea (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = thee (err = 2) => Prob = 7.142137028717453e-07 <= prior = 2.3523344657712718e-05, likelihood = 0.1353352832366127\n",
      ".. c = thud (err = 2) => Prob = 3.5712192873834694e-07 <= prior = 9.047440252966429e-06, likelihood = 0.1353352832366127\n",
      ".. c = oh (err = 2) => Prob = 4.994435288056964e-06 <= prior = 0.0003709450503716236, likelihood = 0.1353352832366127\n",
      ".. c = ti (err = 2) => Prob = 1.428499023497197e-06 <= prior = 6.333208177076501e-06, likelihood = 0.1353352832366127\n",
      ".. c = ah (err = 2) => Prob = 2.141533546480567e-06 <= prior = 0.00020085317361585473, likelihood = 0.1353352832366127\n",
      ".. c = la (err = 2) => Prob = 3.570795270697897e-07 <= prior = 4.976092139131536e-05, likelihood = 0.1353352832366127\n",
      ".. c = toi (err = 2) => Prob = 3.5712946786702493e-07 <= prior = 1.8094880505932859e-06, likelihood = 0.1353352832366127\n",
      ".. c = that (err = 2) => Prob = 1.2791516643347315e-05 <= prior = 0.011320157244511596, likelihood = 0.1353352832366127\n",
      ".. c = sa (err = 2) => Prob = 3.5712758305501367e-07 <= prior = 3.6189761011865717e-06, likelihood = 0.1353352832366127\n",
      ".. c = tr (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = wh (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = eva (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = twas (err = 2) => Prob = 3.5712852545853246e-07 <= prior = 2.714232075889929e-06, likelihood = 0.1353352832366127\n",
      ".. c = htm (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = has (err = 2) => Prob = 3.556270154475126e-07 <= prior = 0.0014503046725505187, likelihood = 0.1353352832366127\n",
      ".. c = lea (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = tear (err = 2) => Prob = 3.571087360290592e-07 <= prior = 2.1713856607119432e-05, likelihood = 0.1353352832366127\n",
      ".. c = thank (err = 2) => Prob = 3.5703242591229977e-07 <= prior = 9.499812265614751e-05, likelihood = 0.1353352832366127\n",
      ".. c = chi (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = ra (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = tit (err = 2) => Prob = 3.5712475587429926e-07 <= prior = 6.333208177076501e-06, likelihood = 0.1353352832366127\n",
      ".. c = whoa (err = 2) => Prob = 3.5712946786702493e-07 <= prior = 1.8094880505932859e-06, likelihood = 0.1353352832366127\n",
      ".. c = va (err = 2) => Prob = 3.5712475587429926e-07 <= prior = 6.333208177076501e-06, likelihood = 0.1353352832366127\n",
      ".. c = hata (err = 2) => Prob = 3.5712946786702493e-07 <= prior = 1.8094880505932859e-06, likelihood = 0.1353352832366127\n",
      ".. c = he (err = 2) => Prob = 5.878850280623111e-06 <= prior = 0.01121973065770367, likelihood = 0.1353352832366127\n",
      ".. c = hat (err = 2) => Prob = 3.5703242591229977e-07 <= prior = 9.499812265614751e-05, likelihood = 0.1353352832366127\n",
      ".. c = two (err = 2) => Prob = 7.121241774248279e-07 <= prior = 0.0010295987007875797, likelihood = 0.1353352832366127\n",
      ".. c = than (err = 2) => Prob = 3.5599839865269534e-07 <= prior = 0.0010911212945077513, likelihood = 0.1353352832366127\n",
      ".. c = hay (err = 2) => Prob = 3.570917754064394e-07 <= prior = 3.7999249062459004e-05, likelihood = 0.1353352832366127\n",
      ".. c = tss (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = ta (err = 2) => Prob = 1.0713770947886914e-06 <= prior = 5.428464151779858e-06, likelihood = 0.1353352832366127\n",
      ".. c = tic (err = 2) => Prob = 3.5712852545853246e-07 <= prior = 2.714232075889929e-06, likelihood = 0.1353352832366127\n",
      ".. c = thus (err = 2) => Prob = 3.5693167117206244e-07 <= prior = 0.00019180573336288832, likelihood = 0.1353352832366127\n",
      ".. c = ka (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = via (err = 2) => Prob = 3.5712852545853246e-07 <= prior = 2.714232075889929e-06, likelihood = 0.1353352832366127\n",
      ".. c = she (err = 2) => Prob = 1.4138035371038447e-06 <= prior = 0.003570119923820553, likelihood = 0.1353352832366127\n",
      ".. c = ham (err = 2) => Prob = 3.571256982628971e-07 <= prior = 5.428464151779858e-06, likelihood = 0.1353352832366127\n",
      ".. c = ch (err = 2) => Prob = 3.5712852545853246e-07 <= prior = 2.714232075889929e-06, likelihood = 0.1353352832366127\n",
      ".. c = ba (err = 2) => Prob = 3.5712946786702493e-07 <= prior = 1.8094880505932859e-06, likelihood = 0.1353352832366127\n",
      ".. c = chas (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = ho (err = 2) => Prob = 1.7856143555601213e-06 <= prior = 8.142696227669786e-06, likelihood = 0.1353352832366127\n",
      ".. c = thou (err = 2) => Prob = 7.141835508128788e-07 <= prior = 3.7999249062459004e-05, likelihood = 0.1353352832366127\n",
      ".. c = shak (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = sham (err = 2) => Prob = 3.5712946786702493e-07 <= prior = 1.8094880505932859e-06, likelihood = 0.1353352832366127\n",
      ".. c = trap (err = 2) => Prob = 3.570917754064394e-07 <= prior = 3.7999249062459004e-05, likelihood = 0.1353352832366127\n",
      ".. c = tag (err = 2) => Prob = 3.5712946786702493e-07 <= prior = 1.8094880505932859e-06, likelihood = 0.1353352832366127\n",
      ".. c = who (err = 2) => Prob = 1.0628397562044028e-06 <= prior = 0.002759469277154761, likelihood = 0.1353352832366127\n",
      ".. c = oka (err = 2) => Prob = 3.5712946786702493e-07 <= prior = 1.8094880505932859e-06, likelihood = 0.1353352832366127\n",
      ".. c = h (err = 2) => Prob = 1.0711707508900038e-06 <= prior = 7.147477799843479e-05, likelihood = 0.1353352832366127\n",
      ".. c = shy (err = 2) => Prob = 3.571115629561358e-07 <= prior = 1.8999624531229502e-05, likelihood = 0.1353352832366127\n",
      ".. c = tub (err = 2) => Prob = 3.5712758305501367e-07 <= prior = 3.6189761011865717e-06, likelihood = 0.1353352832366127\n",
      ".. c = pa (err = 2) => Prob = 7.14234433889123e-07 <= prior = 1.3571160379449644e-05, likelihood = 0.1353352832366127\n",
      ".. c = they (err = 2) => Prob = 1.0603748076070037e-06 <= prior = 0.00356288197161818, likelihood = 0.1353352832366127\n",
      ".. c = til (err = 2) => Prob = 3.5712946786702493e-07 <= prior = 1.8094880505932859e-06, likelihood = 0.1353352832366127\n",
      ".. c = theah (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = tm (err = 2) => Prob = 3.570107635522218e-07 <= prior = 0.0001158072352379703, likelihood = 0.1353352832366127\n",
      ".. c = had (err = 2) => Prob = 1.611409565009599e-05 <= prior = 0.006679725138765115, likelihood = 0.1353352832366127\n",
      ".. c = khan (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = then (err = 2) => Prob = 7.113381456765159e-07 <= prior = 0.0014095911914121697, likelihood = 0.1353352832366127\n",
      ".. c = takh (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = tim (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = hi (err = 2) => Prob = 3.5712946786702493e-07 <= prior = 1.8094880505932859e-06, likelihood = 0.1353352832366127\n",
      ".. c = sea (err = 2) => Prob = 3.570540909013535e-07 <= prior = 7.418901007432472e-05, likelihood = 0.1353352832366127\n",
      ".. c = chap (err = 2) => Prob = 3.5712287111202423e-07 <= prior = 8.142696227669786e-06, likelihood = 0.1353352832366127\n",
      ".. c = tip (err = 2) => Prob = 3.57123813490675e-07 <= prior = 7.2379522023731435e-06, likelihood = 0.1353352832366127\n",
      ".. c = ha (err = 2) => Prob = 1.2854184664160395e-05 <= prior = 6.785580189724822e-05, likelihood = 0.1353352832366127\n",
      ".. c = da (err = 2) => Prob = 7.142551661100273e-07 <= prior = 3.6189761011865717e-06, likelihood = 0.1353352832366127\n",
      ".. c = tsar (err = 2) => Prob = 3.570785849248502e-07 <= prior = 5.0665665416612006e-05, likelihood = 0.1353352832366127\n",
      ".. c = this (err = 2) => Prob = 1.0600287449279611e-06 <= prior = 0.0036759749747802602, likelihood = 0.1353352832366127\n",
      ".. c = oho (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = at (err = 2) => Prob = 7.01688088082774e-07 <= prior = 0.006144116675789502, likelihood = 0.1353352832366127\n",
      ".. c = tom (err = 2) => Prob = 3.5712758305501367e-07 <= prior = 3.6189761011865717e-06, likelihood = 0.1353352832366127\n",
      ".. c = bah (err = 2) => Prob = 3.5712946786702493e-07 <= prior = 1.8094880505932859e-06, likelihood = 0.1353352832366127\n",
      ".. c = thaw (err = 2) => Prob = 3.5712946786702493e-07 <= prior = 1.8094880505932859e-06, likelihood = 0.1353352832366127\n",
      ".. c = utah (err = 2) => Prob = 3.571115629561358e-07 <= prior = 1.8999624531229502e-05, likelihood = 0.1353352832366127\n",
      ".. c = why (err = 2) => Prob = 1.0694918662096494e-06 <= prior = 0.0006097974730499374, likelihood = 0.1353352832366127\n",
      ".. c = boa (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = top (err = 2) => Prob = 3.570917754064394e-07 <= prior = 3.7999249062459004e-05, likelihood = 0.1353352832366127\n",
      ".. c = hm (err = 2) => Prob = 1.4284877149533877e-06 <= prior = 9.047440252966429e-06, likelihood = 0.1353352832366127\n",
      ".. c = eh (err = 2) => Prob = 7.14094993861401e-07 <= prior = 8.052221825140122e-05, likelihood = 0.1353352832366127\n",
      ".. c = tula (err = 2) => Prob = 3.57123813490675e-07 <= prior = 7.2379522023731435e-06, likelihood = 0.1353352832366127\n",
      ".. c = tis (err = 2) => Prob = 3.571266406564686e-07 <= prior = 4.5237201264832144e-06, likelihood = 0.1353352832366127\n",
      ".. c = ted (err = 2) => Prob = 3.5712946786702493e-07 <= prior = 1.8094880505932859e-06, likelihood = 0.1353352832366127\n",
      ".. c = tar (err = 2) => Prob = 3.5712475587429926e-07 <= prior = 6.333208177076501e-06, likelihood = 0.1353352832366127\n",
      ".. c = shah (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = ga (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = ja (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n",
      ".. c = tz (err = 2) => Prob = 3.5713041028049123e-07 <= prior = 9.047440252966429e-07, likelihood = 0.1353352832366127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ha'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('tha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can see the best candidate for 'the' is 'ha'"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
